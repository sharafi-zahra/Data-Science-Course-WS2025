{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7540b1084866dac",
   "metadata": {},
   "source": [
    "# Beautiful soup Introduction: Examples\n",
    "\n",
    "This notebook is intended to give you an introduction to the basic functionalities of the **`Beautiful soup`** library.  \n",
    "\n",
    "The goal is to:\n",
    "\n",
    "1. **parse HTML reliably**\n",
    "2. **locate elements**\n",
    "3. **extract clean text/links**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a65a90f9595928",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8436c8a6adf4c",
   "metadata": {},
   "source": [
    "The **`Beautiful soup`** library is not native to Python, so we need to start by importing it:  \n",
    "\n",
    "```bash\n",
    "pip install requests beautifulsoup4 lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840e91623b597e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:47:49.372187Z",
     "start_time": "2025-09-24T14:47:48.613816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d97c2405cd0200f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:48:46.887024Z",
     "start_time": "2025-09-24T14:48:46.654820Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:48:47.455693Z",
     "start_time": "2025-09-24T14:48:47.453768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper: create a soup object from a URL\n",
    "def get_soup(url, *, parser=\"lxml\"):\n",
    "    resp = requests.get(url, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d495fa8ed28",
   "metadata": {},
   "source": [
    "Beautiful Soup turns your HTML into a **tree**. You can:\n",
    "1. **Find one** element (`find`)\n",
    "2. **Find many** elements (`find_all` / `select`)\n",
    "3. **Filter** by tag name, attributes, text, and CSS selectors\n",
    "4. **Extract** cleaned text (`.get_text`) and attribute values (`.get('href')`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719c0a7a8b2e747",
   "metadata": {},
   "source": [
    "#### 1.1 `find` - grab the **first** match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81247dfb3bd50a8b",
   "metadata": {},
   "source": [
    "**Signature:** `soup.find(tag_name, attrs={...}, string=..., class_=\"...\")`\n",
    "\n",
    "- Returns a **single element** (or `None` if not found)\n",
    "- Great when you expect exactly one main region or header\n",
    "\n",
    "**Example (Simple page):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9270a9b6655eba6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:50:04.023935Z",
     "start_time": "2025-09-24T14:50:03.031539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andorra'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.scrapethissite.com/pages/simple/\"\n",
    "soup = get_soup(url)\n",
    "# Find the first <h3> with class \"country-name\"\n",
    "country_h3 = soup.find(\"h3\", class_=\"country-name\")\n",
    "country_h3.get_text(strip=True) if country_h3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c942456b3470e",
   "metadata": {},
   "source": [
    "**Tips**\n",
    "- Prefer `class_=\"foo\"` instead of `attrs={'class': 'foo'}` (since `class` is a Python keyword)\n",
    "- For IDs, use `id=\"main\"` or `attrs={'id': 'main'}`\n",
    "- Use `.find(...).get_text(strip=True)` to get trimmed text in one go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c28febb3b3636",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. `find_all` - grab **all** matches (list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87a8ee5f213d3",
   "metadata": {},
   "source": [
    "**Signature:** `soup.find_all(tag_name, attrs={...}, limit=None)`\n",
    "\n",
    "- Returns a **list** of elements (possibly empty)\n",
    "- Combine with list comprehensions for fast extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffa92e30848b085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:52:52.122865Z",
     "start_time": "2025-09-24T14:52:52.114211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,\n",
       " ['Andorra',\n",
       "  'United Arab Emirates',\n",
       "  'Afghanistan',\n",
       "  'Antigua and Barbuda',\n",
       "  'Anguilla',\n",
       "  'Albania',\n",
       "  'Armenia',\n",
       "  'Angola',\n",
       "  'Antarctica',\n",
       "  'Argentina',\n",
       "  'American Samoa',\n",
       "  'Austria',\n",
       "  'Australia',\n",
       "  'Aruba',\n",
       "  'Åland'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All countries listed on the Simple page\n",
    "countries = soup.find_all(\"div\", class_=\"country\")\n",
    "len(countries), [c.find(\"h3\", class_=\"country-name\").get_text(strip=True) for c in countries[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8276c454defd35b",
   "metadata": {},
   "source": [
    "*Filtering by attributes**\n",
    "\n",
    "Any HTML attribute can be matched via `attrs`. For example: `attrs={'data-role': 'row'}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206817c150b3972b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. `select` - use **CSS selectors** (power move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37365f195aa61e",
   "metadata": {},
   "source": [
    "**Signature:** `soup.select(\"css selector\")` (many) and `soup.select_one(\"css selector\")` (first)\n",
    "\n",
    "- Readable and **very flexible**\n",
    "- Supports descendant selectors, classes, IDs, attribute selectors, `:has()`, `:contains()` **(limited in BS4)**\n",
    "\n",
    "**Example (Hockey Teams page):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "602dc44a343113cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:53:45.732458Z",
     "start_time": "2025-09-24T14:53:45.235709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_url = \"https://www.scrapethissite.com/pages/forms/?page_num=1\"\n",
    "teams_soup = get_soup(teams_url)\n",
    "\n",
    "# Each team is a row with class 'team'\n",
    "team_rows = teams_soup.select(\".team\")\n",
    "len(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aca1b1773d9a24da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:53:50.958707Z",
     "start_time": "2025-09-24T14:53:50.954389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Team': 'Boston Bruins', 'Year': '1990', 'Wins': '44', 'Losses': '24'},\n",
       " {'Team': 'Buffalo Sabres', 'Year': '1990', 'Wins': '31', 'Losses': '30'},\n",
       " {'Team': 'Calgary Flames', 'Year': '1990', 'Wins': '46', 'Losses': '26'},\n",
       " {'Team': 'Chicago Blackhawks', 'Year': '1990', 'Wins': '49', 'Losses': '23'},\n",
       " {'Team': 'Detroit Red Wings', 'Year': '1990', 'Wins': '34', 'Losses': '38'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract a few columns with CSS selectors\n",
    "def parse_team_row(row):\n",
    "    return {\n",
    "        \"Team\": row.select_one(\".name\").get_text(strip=True) if row.select_one(\".name\") else None,\n",
    "        \"Year\": row.select_one(\".year\").get_text(strip=True) if row.select_one(\".year\") else None,\n",
    "        \"Wins\": row.select_one(\".wins\").get_text(strip=True) if row.select_one(\".wins\") else None,\n",
    "        \"Losses\": row.select_one(\".losses\").get_text(strip=True) if row.select_one(\".losses\") else None,\n",
    "    }\n",
    "\n",
    "[parse_team_row(r) for r in team_rows[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc047d46054e6108",
   "metadata": {},
   "source": [
    "**Selector mini-cheat sheet**\n",
    "\n",
    "- `.class` — elements with class\n",
    "- `#id` — element with ID\n",
    "- `tag[attr=\"value\"]` — attribute equals value (quotes optional for simple values)\n",
    "- `a[href^=\"/pages/\"]` — attribute **starts with** `/pages/`\n",
    "- `div.country .country-name` — descendant selection\n",
    "- `div.country > h3.country-name` — **direct child** only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62876dd324a57b85",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.  `get_text` - extract **clean text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf75f961cd8dc7",
   "metadata": {},
   "source": [
    "**Signature:** `element.get_text(separator=\"\", strip=False)`\n",
    "\n",
    "- Collapses nested tags to a single string\n",
    "- `strip=True` trims whitespace\n",
    "- Use `separator=\" \"` to insert spaces between nodes if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58e5dbd7f2bb2f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:54:44.887843Z",
     "start_time": "2025-09-24T14:54:44.885351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andorra Capital: Andorra la Vella Population: 84000 Area (km 2 ): 468.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get country block text and clean it\n",
    "block = countries[0] if countries else None\n",
    "block.get_text(\" \", strip=True) if block else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5fbff9aa7157d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Attributes - grab links, titles, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0586b2e4f9c67",
   "metadata": {},
   "source": [
    "Use `element.get('href')` (safe; returns `None` if missing) or `element['href']` (raises KeyError if missing).\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d9b5a95c08f6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:55:28.971565Z",
     "start_time": "2025-09-24T14:55:28.593764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Scrape This Site', '/'),\n",
       " ('Sandbox', '/pages/'),\n",
       " ('Lessons', '/lessons/'),\n",
       " ('FAQ', '/faq/'),\n",
       " ('Login', '/login/'),\n",
       " ('Countries of the World: A Simple Example', '/pages/simple/'),\n",
       " ('Hockey Teams: Forms, Searching and Pagination', '/pages/forms/'),\n",
       " ('Oscar Winning Films: AJAX and Javascript', '/pages/ajax-javascript/'),\n",
       " ('Turtles All the Way Down: Frames & iFrames', '/pages/frames/'),\n",
       " (\"Advanced Topics: Real World Challenges You'll Encounter\",\n",
       "  '/pages/advanced/')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the \"Oscar Winners\" example page, get links from the sidebar\n",
    "oscars_url = \"https://www.scrapethissite.com/pages/\"\n",
    "oscars_soup = get_soup(oscars_url)\n",
    "\n",
    "links = [(a.get_text(strip=True), a.get('href')) for a in oscars_soup.select('a')[:10]]\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbcaec437d246c1",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.  Pulling it together - small scraping routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6aa19b92174cae",
   "metadata": {},
   "source": [
    "We'll scrape the **Simple** countries and build a structured list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aecc9e7e20c6e846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:56:04.846810Z",
     "start_time": "2025-09-24T14:56:03.858832Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2946688476.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"name\": ???,\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def scrape_simple_countries(page_url=\"https://www.scrapethissite.com/pages/simple/\"):\n",
    "    ??? = get_soup(???)\n",
    "    items = []\n",
    "    for block in soup.select(\".???\"):\n",
    "        name = block.select_one(\".country-name\").get_text(strip=True)\n",
    "        capital = block.select_one(\".country-capital\").get_text(strip=True)\n",
    "        population = block.select_one(\".country-population\").get_text(strip=True)\n",
    "        area_km2 = block.select_one(\".country-area\").get_text(strip=True)\n",
    "        items.append({\n",
    "            \"name\": ???,\n",
    "            \"???\": capital,\n",
    "            \"population\": population,\n",
    "            \"area_km2\": area_km2,\n",
    "        })\n",
    "    return ???\n",
    "\n",
    "countries_data = scrape_simple_countries()\n",
    "countries_data[:???]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a290da36d1e32a",
   "metadata": {},
   "source": [
    "---\n",
    "## Pagination pattern (when pages=1,2,3…)\n",
    "\n",
    "Some pages paginate via `?page_num=...`. You can loop until no results are returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e677a96b1ddc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T14:57:13.059870Z",
     "start_time": "2025-09-24T14:57:12.536714Z"
    }
   },
   "outputs": [],
   "source": [
    "def iterate_hockey_pages(base=\"https://www.scrapethissite.com/pages/forms/?page_num={}\"):\n",
    "    page = ???\n",
    "    while ???:\n",
    "        soup = ???(base.format(page))\n",
    "        rows = soup.select('.team')\n",
    "        if not rows:\n",
    "            break\n",
    "        for r in rows:\n",
    "            yield parse_team_row(r)\n",
    "        page += 1\n",
    "\n",
    "# Peek at the first 8 rows across pages (this may take a moment to run)\n",
    "from itertools import islice\n",
    "list(islice(iterate_hockey_pages(), 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83c611d351d644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
